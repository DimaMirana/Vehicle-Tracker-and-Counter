{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "from scipy import spatial\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "FRAMES_BEFORE_CURRENT = 10\n",
    "preDefinedConfidence = 0.5\n",
    "preDefinedThreshold = 0.5\n",
    "inputWidth, inputHeight = 416, 416 #Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading yolo\n",
    "LABELS = open('./yolo/coco.names').read().strip().split(\"\\n\")\n",
    "yolo_weights = './yolo/yolov3.weights'\n",
    "yolo_cfg = './yolo/yolov3.cfg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object want to count\n",
    "list_of_vehicles = [\"bicycle\", \"car\", \"motorbike\", \"bus\", \"truck\", \"train\"]\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get frame and time\n",
    "def countFPS(start_time, num_frames):\n",
    "    current_time = int(time.time())\n",
    "    if(current_time > start_time):\n",
    "        os.system('clear')\n",
    "        num_frames = 0\n",
    "        start_time = current_time\n",
    "    return start_time, num_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display number of detected vehicles on frame\n",
    "def displayCount(frame, vehicle_count):\n",
    "    cv2.putText(frame,'Detected Vehicles: ' + str(vehicle_count),(20, 20),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,0.8,(0, 255, 0),5,cv2.FONT_HERSHEY_COMPLEX_SMALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw rectangle on detected cars (chq if box exist->flatten the array->get corners for rec,draw rec and circle)\n",
    "def drawDetectionBoxes(idxs, boxes, classIDs, confidences, frame):\n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten():\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            color = [int(c) for c in COLORS[classIDs[i]]]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            text = \"{}: {:.4f}\".format(LABELS[classIDs[i]],confidences[i])\n",
    "            cv2.putText(frame, text, (x, y - 5),cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "            cv2.circle(frame, (x + (w//2), y + (h//2)), 2, (0, 0xFF, 0), thickness=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chq new detected box already in previous frames or not\n",
    "def boxInPreviousFrames(previous_frame_detections, current_box, current_detections):\n",
    "    centerX, centerY, width, height = current_box\n",
    "    dist = np.inf  \n",
    "    for i in range(FRAMES_BEFORE_CURRENT):\n",
    "        coordinate_list = list(previous_frame_detections[i].keys())\n",
    "        if len(coordinate_list) == 0:  \n",
    "            continue\n",
    "        temp_dist, index = spatial.KDTree(\n",
    "            coordinate_list).query([(centerX, centerY)])\n",
    "        if (temp_dist < dist):\n",
    "            dist = temp_dist\n",
    "            frame_num = i\n",
    "            coord = coordinate_list[index[0]]\n",
    "\n",
    "    if (dist > (max(width, height)/2)):\n",
    "        return False\n",
    "    current_detections[(centerX, centerY)] = previous_frame_detections[frame_num][coord]\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the no of vehicles\n",
    "def count_vehicles(idxs, boxes, classIDs, vehicle_count, previous_frame_detections, frame):\n",
    "    current_detections = {}\n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten():\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "\n",
    "            centerX = x + (w//2)\n",
    "            centerY = y + (h//2)\n",
    "            if (LABELS[classIDs[i]] in list_of_vehicles):\n",
    "                current_detections[(centerX, centerY)] = vehicle_count\n",
    "                if (not boxInPreviousFrames(previous_frame_detections, (centerX, centerY, w, h), current_detections)):\n",
    "                    vehicle_count += 1\n",
    "                ID = current_detections.get((centerX, centerY))\n",
    "                if (list(current_detections.values()).count(ID) > 1):\n",
    "                    current_detections[(centerX, centerY)] = vehicle_count\n",
    "                    vehicle_count += 1\n",
    "                cv2.putText(frame, str(ID), (centerX, centerY),cv2.FONT_HERSHEY_SIMPLEX, 0.5, [0, 0, 255], 2)\n",
    "    return vehicle_count, current_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load yolo from disk\n",
    "net = cv2.dnn.readNetFromDarknet(yolo_cfg, yolo_weights)\n",
    "\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_frame_detections = [{(0, 0): 0} for i in range(FRAMES_BEFORE_CURRENT)]\n",
    "num_frames, vehicle_count = 0, 0\n",
    "start_time = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] cleaning up...\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('test_data.mp4')\n",
    "video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "    print('ERROR FILE NOT FOUND, OR WRONG CODEC USE!')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read();\n",
    "    if ret == True:\n",
    "        num_frames += 1\n",
    "        boxes, confidences, classIDs = [], [], []\n",
    "        start_time, num_frames = countFPS(start_time, num_frames)\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (inputWidth, inputHeight),swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        start = time.time()\n",
    "        layerOutputs = net.forward(ln)\n",
    "        end = time.time()\n",
    "        for output in layerOutputs:\n",
    "            for i, detection in enumerate(output):\n",
    "                scores = detection[5:]\n",
    "                classID = np.argmax(scores)\n",
    "                confidence = scores[classID]\n",
    "                if confidence > preDefinedConfidence:\n",
    "                    box = detection[0:4] * np.array([video_width, video_height, video_width, video_height])\n",
    "                    (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                    x = int(centerX - (width / 2))\n",
    "                    y = int(centerY - (height / 2))\n",
    "                    boxes.append([x, y, int(width), int(height)])\n",
    "                    confidences.append(float(confidence))\n",
    "                    classIDs.append(classID)\n",
    "\n",
    "        idxs = cv2.dnn.NMSBoxes(boxes, confidences, preDefinedConfidence,preDefinedThreshold)\n",
    "        drawDetectionBoxes(idxs, boxes, classIDs, confidences, frame)\n",
    "        vehicle_count, current_detections = count_vehicles(idxs, boxes, classIDs, vehicle_count, previous_frame_detections, frame)\n",
    "        displayCount(frame, vehicle_count)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        previous_frame_detections.pop(0)\n",
    "        previous_frame_detections.append(current_detections)\n",
    "        \n",
    "        if (cv2.waitKey(10) & 0xFF == ord('q')):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "print(\"[INFO] cleaning up...\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
